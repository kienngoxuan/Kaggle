{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":85723,"databundleVersionId":10652996,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\nfrom lightgbm import early_stopping  \nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\nfrom sklearn.preprocessing import StandardScaler\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e1/train.csv')\ntrain = train.drop(columns=['id'])\n\ntrain = train.drop_duplicates()\ntrain = train.dropna(subset=['num_sold'])\n\ntest = pd.read_csv('/kaggle/input/playground-series-s5e1/test.csv')\ntest_id = test['id']\ntest = test.drop(columns=['id'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eda(df):\n    df['date'] = pd.to_datetime(df['date'])\n    df['year'] = df['date'].dt.year\n    df['day'] = df['date'].dt.day\n    df['month'] = df['date'].dt.month\n    df['quarter'] = df['date'].dt.quarter\n    df['month_name'] = df['date'].dt.month_name()\n    df['day_of_week'] = df['date'].dt.day_name()\n    df['week'] = df['date'].dt.isocalendar().week\n    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12) \n    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n    df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)\n    df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)\n    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)  \n    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n    df['group'] = (df['year'] - 2020) * 48 + df['month'] * 4 + df['day'] // 7\n    df.drop('date', axis=1, inplace=True)\n    df['cos_year'] = np.cos(df['year'] * (2 * np.pi) / 100)\n    df['sin_year'] = np.sin(df['year'] * (2 * np.pi) / 100)\n    # why using sin/cos? to tell model that after Dec we have Jan, of we dont do this it will\n    # consider 1 to 12 and then 12 to 1 wont be considered. same applies on week day also\n    # this is universal funnction whenever we have date.\n    dummy_prefixes = ['country', 'store', 'product','month_name','day_of_week']\n    df = pd.get_dummies(df, columns=dummy_prefixes, drop_first=True)\n\n    return df\n\ntrain = eda(train)\ntest = eda(test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train.drop(['num_sold'], axis=1)\ny = train['num_sold']\nX_test = test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nimport numpy as np\nfrom sklearn.model_selection import RepeatedKFold\nfrom catboost import CatBoostRegressor\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\nimport shap\n\n# Define RMSLE function\ndef rmsle(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.maximum(np.array(y_pred), 0)\n    return np.sqrt(np.mean((np.log1p(y_true) - np.log1p(y_pred)) ** 2))\n\n\nparams2 = {'n_estimators': 1327, 'max_depth': 7, 'colsample_bytree': 0.6932974324289563, \n          'subsample': 0.10409176504249848, 'learning_rate': 0.03556720266195535, 'min_child_samples': 78}\n\nparams1 = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmse',\n    'n_estimators': 1000,\n    'learning_rate': 0.08,\n    'max_depth': 13,\n    'reg_alpha': 0.01,\n    'lambda_l2': 0.01,  \n    'min_child_samples' : 32,\n    'colsample_bytree': 0.93,\n    'subsample': 0.7, \n    'seed': 42,\n    'verbose': -1,\n    'device' : 'cpu' \n}\ndef training(params, modelName, X, y, X_test):\n    kfold = RepeatedKFold(n_splits=10, n_repeats=1, random_state=42)\n    fold_test_preds = []  # List to store test predictions from each fold\n    rmsle_values = []  # List to store RMSLE for each fold\n    modelM = None\n    for fold, (train_idx, val_idx) in enumerate(tqdm(kfold.split(X, y), desc=\"Training Folds\", total=10)):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        \n        # Apply log transformation to target variables\n        y_train_log = np.log1p(y_train)\n        y_val_log = np.log1p(y_val)\n        \n        # Initialize model based on modelName\n        if modelName == \"lgbm\":\n            model = lgb.LGBMRegressor(**params)\n        elif modelName == \"catboost\":\n            model = CatBoostRegressor(**params, random_state=42)  # Silent=True for less verbose\n        \n    \n        model.fit(X_train, y_train_log,\n                      eval_set=[(X_val, y_val_log)],\n                      callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)])\n        modelM = model\n        \n        y_val_pred_log = model.predict(X_val)\n        y_val_pred = np.expm1(y_val_pred_log)\n        \n        #RMSLE\n        rmsle_valid = rmsle(y_val, y_val_pred)\n        rmsle_values.append(rmsle_valid)\n        \n        # Predict on the test set\n        test_log_pred = model.predict(X_test)\n        test_pred = np.expm1(test_log_pred)\n        \n    \n        fold_test_preds.append(test_pred)\n        clear_output(wait=True)\n        \n\n    return fold_test_preds, np.mean(rmsle_values)\n\nans = training(params1,'lgbm', X, y, X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_test_pred = np.mean(ans[0], axis = 0)\nrmsle_values = ans[1]\nprint(f'LGBM {rmsle_values}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = final_test_pred","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = pd.DataFrame({\n    'id': test_id,\n    'num_sold': preds\n})\npredictions.to_csv('ans.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}